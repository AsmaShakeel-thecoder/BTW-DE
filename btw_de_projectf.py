# -*- coding: utf-8 -*-
"""BTW-DE_Projectf1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mWK9hAb5_ZsscfedCxiws_LGMWFSowDp

# BWT-DE Project 1

## Logging Function
"""

import logging

# Remove all handlers associated with the root logger object
for handler in logging.root.handlers[:]:
    logging.root.removeHandler(handler)

# Set up logging
logging.basicConfig(filename='./bank_data.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def log_message(message):
    logging.info(message)

"""## Data Extraction"""

import requests
import pandas as pd
from bs4 import BeautifulSoup

def scrape_data(url):
    log_message('Starting data extraction from Wikipedia')
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')

    # Find all tables with the class 'wikitable'
    tables = soup.find_all('table', {'class': 'wikitable'})

    # Check if we have enough tables
    if len(tables) < 2:
        log_message('Not enough tables found.')
        return None, None

    # Extract data from the first table
    headers1 = [header.text.strip() for header in tables[0].find_all('th')]
    rows1 = []
    for row in tables[0].find_all('tr')[1:]:
        rows1.append([cell.text.strip() for cell in row.find_all(['td', 'th'])])
    df1 = pd.DataFrame(rows1, columns=headers1)

    # Extract data from the second table
    headers2 = [header.text.strip() for header in tables[1].find_all('th')]
    rows2 = []
    for row in tables[1].find_all('tr')[1:]:
        rows2.append([cell.text.strip() for cell in row.find_all(['td', 'th'])])
    df2 = pd.DataFrame(rows2, columns=headers2)

    log_message('Data extraction completed')
    return df1, df2

url = 'https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks'
df1, df2 = scrape_data(url)

# Print the first few rows of each DataFrame
print(df1.head())
print(df2.head())

"""## Data Transformation

### Merge df1 and df2 to create banks_df
"""

log_message('Starting data transformation')

# Merge df1 and df2 based on 'Bank name'
banks_df = pd.merge(df1, df2[['Bank name', 'Total assets(2022)(US$ billion)']],
                     left_on='Bank name',
                     right_on='Bank name',
                     how='left')

print(banks_df)

"""### Remove null values"""

# Remove null values
banks_df.dropna(inplace=True)
banks_df

"""### Create New Column

"""

exchange_rate = pd.read_csv('/content/exchange_rate.csv')
exchange_rate

# Remove commas and convert 'Total assets(2022)(US$ billion)' to numeric
banks_df['Total assets(2022)(US$ billion)'] = banks_df['Total assets(2022)(US$ billion)'].str.replace(',', '', regex=False).astype(float)

# Get the EUR exchange rate
eur_rate = exchange_rate.loc[exchange_rate['Currency'] == 'EUR', 'Rate'].values[0]

# Calculate total assets in EUR
banks_df['Total assets(2022)(EUR billion)'] = banks_df['Total assets(2022)(US$ billion)'] * eur_rate

print(banks_df)

log_message('Data Transformation Completed')

"""## Visualization"""

import matplotlib.pyplot as plt

log_message('Starting data visualizing')
# Bar Chart for Market Capitalization
plt.figure(figsize=(10, 6))
plt.bar(banks_df['Bank name'], banks_df['Market cap(US$ billion)'], color='skyblue')
plt.xlabel('Bank Name')
plt.ylabel('Market Cap (US$ Billion)')
plt.title('Market Capitalization of Banks')
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.show()

# Bar Chart for Total Assets in EUR
plt.figure(figsize=(10, 6))
plt.barh(banks_df['Bank name'], banks_df['Total assets(2022)(EUR billion)'], color='lightgreen')
plt.xlabel('Total Assets (EUR Billion)')
plt.title('Total Assets of Banks in EUR')
plt.grid(axis='x')
plt.show()

# Scatter Plot for Market Cap vs Total Assets in EUR
plt.figure(figsize=(10, 6))
plt.scatter(banks_df['Market cap(US$ billion)'], banks_df['Total assets(2022)(EUR billion)'], color='purple')
plt.title('Market Cap vs Total Assets in EUR')
plt.xlabel('Market Cap (US$ Billion)')
plt.ylabel('Total Assets (EUR Billion)')
for i, txt in enumerate(banks_df['Bank name']):
    plt.annotate(txt, (banks_df['Market cap(US$ billion)'].iloc[i], banks_df['Total assets(2022)(EUR billion)'].iloc[i]), fontsize=9)
plt.grid()
plt.show()

"""## Loading to .csv"""

def save_to_csv(df, filename):
    log_message(f'Saving data to {filename}')
    df.to_csv(filename, index=False)
    log_message('Data saved to CSV')

# Save to CSV
save_to_csv(banks_df, 'transformed_banks_data.csv')

"""## Loading to Database"""

import sqlite3

def load_to_db(df, db_name):
    log_message('Loading data into SQLite database')
    conn = sqlite3.connect(db_name)
    df.to_sql('banks', conn, if_exists='replace', index=False)
    conn.close()
    log_message('Data loaded into SQLite database')

# Load to database
load_to_db(banks_df, 'banks.db')

"""## Function to Run Queries on Database"""

def run_query(query, db_name='banks.db'):
    log_message(f'Running query: {query}')
    conn = sqlite3.connect(db_name)
    result = pd.read_sql_query(query, conn)
    conn.close()
    log_message('Query executed')
    return result

# Queries
query = 'SELECT * FROM banks'
result_df = run_query(query)

print("\n\nQuery Results: ")
print(result_df)

query = 'SELECT * FROM banks WHERE "Bank name" = "JPMorgan Chase"'
result_df = run_query(query)

print("\n\nQuery Results: ")
print(result_df)

"""## Verify Log enteries"""

def verify_log_entries():
    with open('/content/bank_data.log', 'r') as log_file:
        for line in log_file:
            print(line.strip())

# Verify log entries
verify_log_entries()

